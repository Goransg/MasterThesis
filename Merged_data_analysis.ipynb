{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor as RF\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from keras.layers import LSTM, Dense, Dropout, Masking, Embedding, Bidirectional\n",
    "from keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pymysql"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Connecting to the database and fetching the data for analysis\n",
    "connection = pymysql.connect(host='localhost',\n",
    "                             port = 3306,\n",
    "                             user=input('Enter user: '),\n",
    "                             password=input('Enter password: '),\n",
    "                             database='scatec_data',\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "\n",
    "with connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        # Create a new record\n",
    "        sql = \"select * from inverter_data_short_v2\"\n",
    "        cursor.execute(sql)      \n",
    "        result = cursor.fetchall()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Converting the raw data from the SQL table into a DataFrame\n",
    "rawdata = pd.DataFrame(result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rawdata = rawdata.sort_values('rowid_inv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rawdata = rawdata.drop('ERR0607', axis = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rawdata = rawdata.fillna(value=np.nan)\n",
    "rawdata = rawdata.fillna(0)\n",
    "for col in rawdata.columns:\n",
    "    if rawdata[col].dtype in ('object', '<M8[ns]'):\n",
    "        try:\n",
    "            rawdata[col] = rawdata[col].astype('float64')\n",
    "        except: \n",
    "            pass\n",
    "#ts = rawdata['Ts']\n",
    "rowidinv = rawdata['rowid_inv']\n",
    "rawdata = rawdata.select_dtypes(exclude=['object', '<M8[ns]'])\n",
    "#rawdata['Ts'] = ts\n",
    "rawdata['rowid_inv'] = rowidinv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Limiting data to production hour data\n",
    "rawdata_prd = rawdata[(rawdata[\"Total_Active_Power_Measurement\"]>0)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Limiting data to data without the decided failure type\n",
    "rawdata_prd = rawdata_prd[(rawdata_prd['ERR0607']<=0)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Setting the figure size for the box-and-whiskers-plot\n",
    "sns.set(rc={\"figure.figsize\":(16, 8)})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plotting box-and-whiskers data for a comprehensive amount of columns\n",
    "ax = sns.boxplot(data=rawdata_prd[rawdata_prd.columns[0:10]])\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plotting box-and-whiskers data for a comprehensive amount of columns\n",
    "ax = sns.boxplot(data=rawdata_prd[rawdata_prd.columns[10:20]])\n",
    "ax.set_xticklabels(['Measurement variable %s'%str(i) for  i in range(1,11)],rotation=30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plotting box-and-whiskers data for a comprehensive amount of columns\n",
    "sns.set(font_scale = 2)\n",
    "ax = sns.boxplot(data=rawdata_prd[rawdata_prd.columns[20:30]])\n",
    "ax.set_xticklabels(['Variable %s'%str(i) for  i in range(1,11)],rotation=20)\n",
    "plt.savefig('bwplot.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plotting box-and-whiskers data for a comprehensive amount of columns\n",
    "ax = sns.boxplot(data=rawdata_prd[rawdata_prd.columns[30:40]])\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plotting box-and-whiskers data for a comprehensive amount of columns\n",
    "ax = sns.boxplot(data=rawdata_prd[rawdata_prd.columns[40:50]])\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plotting box-and-whiskers data for a comprehensive amount of columns\n",
    "ax = sns.boxplot(data=rawdata_prd[rawdata_prd.columns[50:59]])\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Removing outlier data based on the box-and-whiskers plots\n",
    "A_1 = rawdata_prd['Section_1_DC_Current_Measurement'].quantile(0.99)\n",
    "A_2 = rawdata_prd['Section_2_DC_Current_Measurement'].quantile(0.99)\n",
    "T_2 = rawdata_prd['Temperature_2-AC_connections_cabinet_ambient_temperature'].quantile(0.99)\n",
    "T_11 = rawdata_prd['Temperature_11-External_ambient_temperature'].quantile(0.99)\n",
    "T_10 = rawdata_prd['Temperature_10-Coolant_temperature_at_the_output_of_the_power_ca'].quantile(0.99)\n",
    "T_9 = rawdata_prd['Total_Active_Energy_fed_into_the_grid_by_inverter'].quantile(0.99)\n",
    "P_IH = rawdata_prd['Liquid_Cooling_input_presure'].quantile(0.99)\n",
    "P_OH = rawdata_prd['Liquid_Cooling_output_presure'].quantile(0.99)\n",
    "P_G1 = rawdata_prd['DC_Energy_generated_from_panels_on_Section_1'].quantile(0.99)\n",
    "P_G2 = rawdata_prd['DC_Energy_generated_from_panels_on_Section_2'].quantile(0.99)\n",
    "P_T = rawdata_prd['Total_Active_Energy_fed_into_the_grid_by_inverter'].quantile(0.99)\n",
    "P_R = rawdata_prd['Total_Capacitive_Reactive_Energy_in_the_inverter'].quantile(0.99)\n",
    "T_M = rawdata_prd['ModuleTemperature'].quantile(0.98)\n",
    "P_2L = rawdata_prd['Section_2_DC_Voltage_Measurement'].quantile(0.02)\n",
    "P_1L = rawdata_prd['Section_1_DC_Voltage_Measurement'].quantile(0.02)\n",
    "P_IL = rawdata_prd['Liquid_Cooling_input_presure'].quantile(0.02)\n",
    "P_OL = rawdata_prd['Liquid_Cooling_output_presure'].quantile(0.02)\n",
    "T_10_L = rawdata_prd['Temperature_10-Coolant_temperature_at_the_output_of_the_power_ca'].quantile(0.01)\n",
    "T_2_L = rawdata_prd['Temperature_11-External_ambient_temperature'].quantile(0.01)\n",
    "S_L = rawdata_prd['SoilingIndex'].quantile(0.02)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rawdata_prd = rawdata_prd[(rawdata_prd['Section_1_DC_Current_Measurement']<A_1)&\n",
    "                         (rawdata_prd['Section_2_DC_Current_Measurement']<A_2)&\n",
    "                            (rawdata_prd['Temperature_2-AC_connections_cabinet_ambient_temperature']<T_2)&\n",
    "                         (rawdata_prd['Temperature_11-External_ambient_temperature']<T_11)&\n",
    "                         (rawdata_prd['Temperature_10-Coolant_temperature_at_the_output_of_the_power_ca']<T_10)&\n",
    "                         (rawdata_prd['Temperature_11-External_ambient_temperature']>T_2_L)&\n",
    "                         (rawdata_prd['Temperature_10-Coolant_temperature_at_the_output_of_the_power_ca']>T_10_L)&\n",
    "                         (rawdata_prd['Temperature_9-Coolant_temperature_at_the_input_of_the_power_cabi']<T_9)&\n",
    "                         (rawdata_prd['Liquid_Cooling_input_presure']<P_IH)&\n",
    "                          (rawdata_prd['Liquid_Cooling_output_presure']<P_OH)&\n",
    "                          (rawdata_prd['DC_Energy_generated_from_panels_on_Section_1']<P_G1)&\n",
    "                          (rawdata_prd['DC_Energy_generated_from_panels_on_Section_2']<P_G2)&\n",
    "                          (rawdata_prd['Section_2_DC_Voltage_Measurement']>P_2L)&\n",
    "                          (rawdata_prd['Section_1_DC_Voltage_Measurement']>P_1L)&\n",
    "                          (rawdata_prd['Liquid_Cooling_input_presure']>0)&\n",
    "                          (rawdata_prd['Liquid_Cooling_output_presure']>0)&\n",
    "                         (rawdata_prd['Total_Active_Energy_fed_into_the_grid_by_inverter']<P_T)&\n",
    "                          (rawdata_prd['Total_Capacitive_Reactive_Energy_in_the_inverter']<P_R)&\n",
    "                         (rawdata_prd['ModuleTemperature']<T_M)&\n",
    "                         (rawdata_prd['SoilingIndex']>S_L)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Resetting index to cope with removed data\n",
    "rawdata_prd = rawdata_prd.reset_index() "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plotting the distribution of cycle length\n",
    "df_max_rul = rawdata_prd[['Cycle_ID', 'RUL']].groupby('Cycle_ID').max()\n",
    "plt.figure(frameon=False, dpi=100)\n",
    "df_max_rul['RUL'].hist(bins=100, figsize=(12, 8))\n",
    "plt.xlim(0)\n",
    "plt.xlabel('Cycle length [Days]', fontsize  = 20)\n",
    "plt.ylabel('Number of cycles', fontsize  = 20)\n",
    "plt.title('Distribution of cycle length', fontsize  = 22)\n",
    "plt.xticks(fontsize  = 18)\n",
    "plt.yticks(fontsize  = 18)\n",
    "plt.savefig('ruldist_v2.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "def evaluate(y_true, y_hat, label='test'):\n",
    "    mse = mean_squared_error(y_true, y_hat)\n",
    "    rmse = np.sqrt(mse)\n",
    "    variance = r2_score(y_true, y_hat)\n",
    "    return [rmse, variance]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def reCycle(dataframe, from_RUL, to_RUL, minimal_length, cycle_column = 'Cycle_ID',\n",
    "            RUL_column = 'RUL', random_state = 1, min_end = 100):\n",
    "    # Truncating maintenance cycles to end at a random point prior to failure\n",
    "    rd = np.random.RandomState(random_state)\n",
    "    newdata = pd.DataFrame()\n",
    "    for cyc in np.unique(dataframe[cycle_column]):\n",
    "        cycsize = len(np.unique(dataframe[(dataframe[cycle_column] == cyc)]['RUL']))\n",
    "        if cycsize >= minimal_length:\n",
    "            try:\n",
    "                new_end = rd.randint((to_RUL+1),min(min_end,(min(cycsize,from_RUL)) - minimal_length))\n",
    "            except: \n",
    "                new_end = to_RUL\n",
    "            print(cyc, ' : ',new_end, ',', cycsize)\n",
    "            recycled = dataframe[(dataframe[RUL_column] >= new_end)&(dataframe[cycle_column] == cyc)]\n",
    "            newdata = newdata.append(recycled, ignore_index = True)\n",
    "        else:\n",
    "            pass\n",
    "    return newdata"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Removing rowid column (Only for PCA-HMM pipeline)\n",
    "rawdata_prd = rawdata_prd.drop('rowid_inv', axis = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "recycled_raw = reCycle(rawdata_prd, 3000, 1, 2,'Cycle_ID','RUL', random_state = 84)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Splitting the data into training and testing data for PCA-HMM by their Cycle-ID\n",
    "trains_hmm, tests_hmm = train_test_split(np.unique(recycled_raw['Cycle_ID']), test_size = 0.3, random_state = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_hmm_trn = rawdata_prd[(rawdata_prd['Cycle_ID'].isin(trains_hmm))]\n",
    "y_hmm_trn = rawdata_prd[(rawdata_prd['Cycle_ID'].isin(trains_hmm))]['RUL']\n",
    "X_hmm_tst = recycled_raw[(recycled_raw['Cycle_ID'].isin(tests_hmm))]\n",
    "y_hmm_tst = recycled_raw[(recycled_raw['Cycle_ID'].isin(tests_hmm))]['RUL']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_hmm_trn = X_hmm_trn.reset_index()\n",
    "y_hmm_trn = y_hmm_trn.reset_index()\n",
    "X_hmm_tst = X_hmm_tst.reset_index()\n",
    "y_hmm_tst = y_hmm_tst.reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "extents_trn = []\n",
    "for cyc in np.unique(X_hmm_trn['Cycle_ID']):\n",
    "    # Adding the locations of the training cycles in the dataset to a list\n",
    "    extents_trn.append((X_hmm_trn[(X_hmm_trn['Cycle_ID'] == cyc)]['RUL'].idxmax(),X_hmm_trn[(X_hmm_trn['Cycle_ID'] == cyc)]['RUL'].idxmin()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "extents_tst = []\n",
    "for cyc in np.unique(X_hmm_tst['Cycle_ID']):\n",
    "    # Adding the locations of the training cycles in the dataset to a list\n",
    "    extents_tst.append((X_hmm_tst[(X_hmm_tst['Cycle_ID'] == cyc)]['RUL'].idxmax(),X_hmm_tst[(X_hmm_tst['Cycle_ID'] == cyc)]['RUL'].idxmin()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_hmm_trn = X_hmm_trn.drop('RUL', axis = 1)\n",
    "X_hmm_tst = X_hmm_tst.drop('RUL', axis = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Performing standard scaling on the data\n",
    "from sklearn.preprocessing import StandardScaler as sc\n",
    "sc = sc()\n",
    "X_hmm_trn = sc.fit_transform(X_hmm_trn)\n",
    "X_hmm_tst = sc.transform(X_hmm_tst)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plotting an explained variance plot for the PCA\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "pca = PCA()\n",
    "pca.fit(X_hmm_trn)\n",
    "data_trn = pca.transform(X_hmm_trn)\n",
    "data_tst = pca.transform(X_hmm_tst)\n",
    "\n",
    "\n",
    "exp_var_cumul = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "fig2 = px.area(\n",
    "    x=range(1, exp_var_cumul.shape[0] + 1),\n",
    "    y=exp_var_cumul,\n",
    "    labels={\"x\": \"# Components\", \"y\": \"Explained Variance\"}, title = 'Explained variance plot for PCA'\n",
    ")\n",
    "fig2.update_layout(title_x=0.5)\n",
    "fig2.update_layout(\n",
    "    font_family=\"Calibri\",\n",
    "    font_color=\"black\",\n",
    "    title_font_family=\"Calibri\",\n",
    "    title_font_color=\"black\",\n",
    "    font_size = 20\n",
    ")\n",
    "fig2.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Performing PCA using three components\n",
    "pca2 = PCA(n_components = 3)\n",
    "pca2.fit(X_hmm_trn)\n",
    "data_trn = pca2.transform(X_hmm_trn)\n",
    "data_test = pca2.transform(X_hmm_tst)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_hmm_trn = pd.DataFrame(data_trn)\n",
    "X_hmm_tst = pd.DataFrame(data_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_hmm_trn = pd.DataFrame(y_hmm_trn)\n",
    "y_hmm_tst = pd.DataFrame(y_hmm_tst)\n",
    "\n",
    "# Start transition matrix for HMM with 15 hidden states\n",
    "transmat = np.array([[0.5,0.125,0.1,0.075,0.05,0.025,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.025],\n",
    "                       [0,0.5,0.125,0.1,0.075,0.05,0.025,0.025,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.025], \n",
    "                       [0,0,0.5,0.125,0.1,0.075,0.05,0.05,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.025], \n",
    "                       [0,0,0,0.5,0.125,0.1,0.075,0.05,0.05,0.025,0.0125,0.0125,0.0125,0.0125,0.025], \n",
    "                       [0,0,0,0,0.5,0.125,0.1,0.075,0.05,0.05,0.025,0.025,0.0125,0.0125,0.025],\n",
    "                     [0,0,0,0,0,0.5,0.125,0.1,0.075,0.05,0.025,0.025,0.025,0.025,0.05],\n",
    "                       [0,0,0,0,0,0,0.5,0.125,0.1,0.075,0.05,0.05,0.025,0.025,0.05], \n",
    "                       [0,0,0,0,0,0,0,0.5,0.2,0.125,0.075,0.05,0.025,0.0125,0.0125], \n",
    "                       [0,0,0,0,0,0,0,0,0.5,0.2,0.125,0.075,0.05,0.025,0.025], \n",
    "                       [0,0,0,0,0,0,0,0,0,0.5,0.2,0.125,0.075,0.05,0.05], \n",
    "                       [0,0,0,0,0,0,0,0,0,0,0.5,0.2,0.125,0.1,0.075], \n",
    "                       [0,0,0,0,0,0,0,0,0,0,0,0.5,0.275,0.125,0.1], \n",
    "                       [0,0,0,0,0,0,0,0,0,0,0,0,0.5,0.3,0.2], \n",
    "                       [0,0,0,0,0,0,0,0,0,0,0,0,0,0.7,0.3], \n",
    "                       [0,0,0,0,0,0,0,0,0,0,0,0,0,0,1]])\n",
    "\n",
    "# Start probability matrix for HMM with 15 hidden states\n",
    "startmat = np.array([1,0,0,0,0,0,0,0,0,0,0,0,0,0,0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pca_ts = PCA(n_components = 6)\n",
    "pca_ts.fit(features_filtered)\n",
    "data = pca_ts.transform(features_filtered)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Start transition matrix for HMM with 10 hidden states\n",
    "\n",
    "transmat = np.array([[0.5,0.175,0.125,0.075,0.05,0.025,0.0125,0.0125,0.0125,0.0125],\n",
    "                       [0,0.5,0.2,0.125,0.075,0.05,0.025,0.0125,0.0125,0], \n",
    "                       [0,0,0.5,0.2,0.125,0.075,0.05,0.025,0.0125,0.0125], \n",
    "                       [0,0,0,0.5,0.2,0.125,0.075,0.05,0.025,0.025], \n",
    "                       [0,0,0,0,0.5,0.2,0.125,0.075,0.05,0.05], \n",
    "                       [0,0,0,0,0,0.5,0.2,0.125,0.1,0.075], \n",
    "                       [0,0,0,0,0,0,0.5,0.275,0.125,0.1], \n",
    "                       [0,0,0,0,0,0,0,0.5,0.3,0.2], \n",
    "                       [0,0,0,0,0,0,0,0,0.7,0.3], \n",
    "                       [0,0,0,0,0,0,0,0,0,1]])\n",
    "# Start probability matrix for HMM with 10 hidden states\n",
    "startmat = np.array([1,0,0,0,0,0,0,0,0,0])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Start transition matrix for HMM with 5 hidden states\n",
    "transmat = np.array([[0.6,0.15,0.1125,0.0875,0.05], \n",
    "                       [0,0.7,0.15,0.1,0.05], \n",
    "                       [0,0,0.7,0.2,0.1], \n",
    "                       [0,0,0,0.8,0.2], \n",
    "                       [0,0,0,0,1]])\n",
    "# Start probability matrix for HMM with 5 hidden states\n",
    "startmat = np.array([1,0,0,0,0])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Removing cycles that are too short for analysis\n",
    "extents_trn = [tup for tup in extents_trn if tup[-1]>(tup[0])]\n",
    "extents_tst = [tup for tup in extents_tst if tup[-1]>(tup[0])]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Training 20 different HMM models with n components and different random states\n",
    "from tqdm import tqdm\n",
    "from hmmlearn import hmm\n",
    "results = []\n",
    "ground_truth = []\n",
    "results_trn = []\n",
    "for RS in tqdm(range(20)):\n",
    "    lr = hmm.GaussianHMM(n_components=10, covariance_type=\"full\", n_iter = 1000, params = 'tmc', init_params = 'mc', random_state=RS)\n",
    "    lr.startprob_ = startmat\n",
    "    lr.transmat_ = transmat\n",
    "    lr.fit(np.concatenate([X_hmm_trn.iloc[extent[0]:extent[1]] for extent in extents_trn if len(X_hmm_trn.iloc[extent[0]:extent[1]])>0]), [len(X_hmm_trn.iloc[extent[0]:extent[1]]) for extent in extents_trn if len(X_hmm_trn.iloc[extent[0]:extent[1]])>0])\n",
    "    preds = []\n",
    "    refs = []\n",
    "    preds_trn = []\n",
    "    refs_trn = []\n",
    "    for split in extents_tst:\n",
    "        preds.append(lr.predict(X_hmm_tst.iloc[split[0]:split[1]]))\n",
    "        refs.append(y_hmm_tst.iloc[split[0]:split[1]].values)\n",
    "    for split in extents_trn:\n",
    "        preds_trn.append(lr.predict(X_hmm_trn.iloc[split[0]:split[1]]))\n",
    "        refs_trn.append(y_hmm_trn.iloc[split[0]:split[1]].values)\n",
    "    results.append(preds)\n",
    "    results_trn.append(preds_trn)\n",
    "    ground_truth.append(refs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Combining the test results from the various HMM's\n",
    "predictions = []\n",
    "for j in range(len(results[0])):\n",
    "    predictions.append([])\n",
    "    for k in range(len(results[0][j])):\n",
    "        pointpreds = []\n",
    "        for m in range(len(results)):\n",
    "            pointpreds.append(results[m][j][k])\n",
    "        predictions[j].append(int(np.mean(pointpreds)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Combining the training results from the various HMM's\n",
    "predictions_trn = []\n",
    "for j in range(len(results_trn[0])):\n",
    "    predictions_trn.append([])\n",
    "    for k in range(len(results_trn[0][j])):\n",
    "        pointpreds_trn = []\n",
    "        for m in range(len(results_trn)):\n",
    "            pointpreds_trn.append(results_trn[m][j][k])\n",
    "        predictions_trn[j].append(int(np.mean(pointpreds_trn)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plotting example cycle development\n",
    "figure(figsize=(16, 9), dpi=80)\n",
    "fig, ax = plt.subplots()\n",
    "for ind, res in range(1,6):\n",
    "    ind += 1\n",
    "    plt.plot(refs[res],predictions[res], label = 'Maintenance cycle %s'%ind, linewidth = 2)      \n",
    "plt.ylabel('Predicted hidden state', fontsize = 16)\n",
    "plt.legend()\n",
    "plt.xlabel('Actual days until failure', fontsize = 16)\n",
    "plt.title('HMM for Inverter failure predictions with feature extraction', fontsize = 24)\n",
    "ax.set_xlim(250,0)\n",
    "ax.set_ylim(0,10)\n",
    "#plt.savefig('HMM_Inv_10_3_diag_invax')\n",
    "plt.show()        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plotting example cycle development as a function of the RUL\n",
    "import numpy as np\n",
    "plotdf = pd.DataFrame()\n",
    "ruls = []\n",
    "states = []\n",
    "reslist = [[] for num in range(11)]\n",
    "for res in range(len(predictions)):\n",
    "    for ind, val in enumerate(predictions[res]):\n",
    "        reslist[val].append(refs[res][ind][0])\n",
    "        ruls.append(refs[res][ind][0])\n",
    "        states.append(val)\n",
    "        \n",
    "plotdf['ruls'] = ruls\n",
    "plotdf['state'] = states\n",
    "\n",
    "allstates = range(15)\n",
    "sns.set(rc={\"figure.figsize\":(21, 16)})\n",
    "sns.set_context(\"paper\", font_scale=2.2) \n",
    "\n",
    "cax = sns.boxplot(x='ruls', y='state', data = plotdf, orient = 'h')\n",
    "cax.set_ylabel('Predicted Hidden state', fontsize = 24)\n",
    "cax.set_title('Time until failure distributed over the predicted hidden state', fontsize = 24)\n",
    "cax.set_xlabel('Actual remaining useful lifetime [Days]', fontsize = 24)\n",
    "cax.set_yticklabels(['State %s\\n count:%d \\n '%(state+1, len(reslist[state])) for state in np.unique(states)])\n",
    "plt.xlim(500,0)\n",
    "plt.ylim(-1,10)\n",
    "fig = cax.get_figure()\n",
    "fig.savefig('HMM_State_count_8_15_diag_flipped_x');"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plotting the distribution of actual RUL for each predicted state for the HMM\n",
    "import numpy as np\n",
    "plotdf = pd.DataFrame()\n",
    "ruls = []\n",
    "states = []\n",
    "reslist = [[] for num in range(11)]\n",
    "for res in range(len(predictions_trn)):\n",
    "    for ind, val in enumerate(predictions_trn[res]):\n",
    "        reslist[val].append(refs_trn[res][ind][0])\n",
    "        ruls.append(refs_trn[res][ind][0])\n",
    "        states.append(val)\n",
    "        \n",
    "plotdf['ruls'] = ruls\n",
    "plotdf['state'] = states\n",
    "\n",
    "allstates = range(15)\n",
    "sns.set(rc={\"figure.figsize\":(21, 16)})\n",
    "sns.set_context(\"paper\", font_scale=2.2) \n",
    "\n",
    "#plt.xlabel('Count = %d'%len(reslist))\n",
    "#plt.ylabel('RUL')\n",
    "#plt.title('HMM for Inverter failure predictions with feature extraction')\n",
    "cax = sns.boxplot(x='ruls', y='state', data = plotdf, orient = 'h')\n",
    "cax.set_ylabel('Predicted Hidden state', fontsize = 24)\n",
    "cax.set_title('Time until failure distributed over the predicted hidden state for Training data', fontsize = 24)\n",
    "cax.set_xlabel('Actual remaining useful lifetime [Days]', fontsize = 24)\n",
    "cax.set_yticklabels(['State %s\\n count:%d \\n '%(state+1, len(reslist[state])) for state in np.unique(states)])\n",
    "plt.xlim(500,0)\n",
    "plt.ylim(-1,10)\n",
    "fig = cax.get_figure()\n",
    "fig.savefig('HMM_State_count_8_15_diag_flipped_x');\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stats = pd.DataFrame()\n",
    "stats['state'] = states\n",
    "stats['RULs'] = ruls\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Preparing data to Wilcoxon test\n",
    "newdf = pd.DataFrame()\n",
    "maxlen = 1150\n",
    "times = []\n",
    "states = []\n",
    "for state in range(10):\n",
    "    if state != 2:\n",
    "        times.extend(plotdf[(plotdf['state'] == state)]['ruls'][:maxlen])\n",
    "        states.extend(plotdf[(plotdf['state'] == state)]['state'][:maxlen]+1)\n",
    "newdf['state'] = states\n",
    "newdf['RULs'] = times"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scikit_posthocs import posthoc_wilcoxon\n",
    "c = posthoc_wilcoxon(newdf, p_adjust = 'bonferroni', group_col = 'state', val_col = 'RULs')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for col in c.columns:    \n",
    "    c[col] = c[(c[col]>0.01)][col]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.heatmap(c, vmax = 0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from numpy.random import choice\n",
    "def make_rul_preds_mean_mc(preds, model,n_states = 10, n_sims = 100, max_iter = 24000):\n",
    "    # Runs a Monte Carlo Simulation to estimate RUL, for each state, based on the transition matrix\n",
    "    mean_vals = []\n",
    "    var = []\n",
    "    results = []\n",
    "    output = np.array(copy.copy(preds))\n",
    "    transmat = model.transmat_\n",
    "    for state in tqdm(range(1,(n_states+1))):\n",
    "        # State = S_n. Iterates through all the states to simulate their transition to the failed, final state\n",
    "        ruls = []\n",
    "        for rs in range(n_sims):\n",
    "            # Runs n_sims simulations of the transition from the state S_n.\n",
    "            steps = 0\n",
    "            cur_state = state\n",
    "            rd = np.random.RandomState(rs)\n",
    "            while steps < max_iter and cur_state < n_states:\n",
    "                # Simulates how many steps it takes from the state S_n to the final state, while updating the current state\n",
    "                # and using the probabilities from that new, current state accordningly\n",
    "                cur_state = rd.choice(np.arange(1, n_states+1), 1, p=transmat[cur_state-1])[0]\n",
    "                steps += 1\n",
    "            ruls.append(steps)\n",
    "        # takes the mean value of the hitting times for the simulations and updates the predicted states to be this mean value\n",
    "        ruls = [rul/26 for rul in ruls]\n",
    "        results.append(ruls)\n",
    "        var.append(np.std(ruls))\n",
    "        state_mean = np.mean(ruls)\n",
    "        output = np.where(output == state, state_mean, output)\n",
    "        mean_vals.append(state_mean)\n",
    "        print(state_mean)\n",
    "    return results, output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trn_sims, output = make_rul_preds_mean_mc(preds, lr, n_states = 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plotting the distribution of simulated RUL for each predicted state for the Monte Carlo simulation\n",
    "\n",
    "import numpy as np\n",
    "plotdf = pd.DataFrame()\n",
    "ruls = []\n",
    "states = []\n",
    "reslist = [[] for num in range(10)]\n",
    "for state_mc in range(len(mc_tst)):\n",
    "    for rul in mc_tst[state_mc]:\n",
    "        reslist[state_mc].append(rul)\n",
    "        ruls.append(rul)\n",
    "        states.append(state_mc)\n",
    "        \n",
    "plotdf['ruls'] = ruls\n",
    "plotdf['state'] = states\n",
    "\n",
    "allstates = range(15)\n",
    "sns.set(rc={\"figure.figsize\":(21, 16)})\n",
    "sns.set_context(\"paper\", font_scale=2.2) \n",
    "\n",
    "cax = sns.boxplot(x='ruls', y='state', data = plotdf, orient = 'h')\n",
    "cax.set_ylabel('Predicted Hidden state', fontsize = 24)\n",
    "cax.set_title('Time until failure distributed over the predicted hidden state', fontsize = 24)\n",
    "cax.set_xlabel('Actual remaining useful lifetime [Days]', fontsize = 24)\n",
    "cax.set_yticklabels(['State %s\\n count:%d \\n '%(state+1, len(reslist[state])) for state in np.unique(states)])\n",
    "plt.xlim(500,0)\n",
    "plt.ylim(-1,10)\n",
    "fig = cax.get_figure()\n",
    "fig.savefig('HMM_MC_State_count_3_10_flipped_x');"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import copy\n",
    "def make_rul_preds_mean(preds, preds_train, refs_train, n_states = 10):\n",
    "    # Uses the distribution of RUL per hidden state in the training data to predict\n",
    "    # the RUL per hidden state in the test data\n",
    "    mean_vals = []\n",
    "    output = np.array(copy.copy(preds))\n",
    "    for state in range(1,(n_states+1)):\n",
    "        ruls = []\n",
    "        for ind in range(len(preds_train)):\n",
    "            if preds_train[ind] == state:\n",
    "                ruls.append(refs_train[ind])\n",
    "        state_mean = np.mean(ruls)\n",
    "        output = np.where(output == state, state_mean, output)\n",
    "        mean_vals.append(state_mean) \n",
    "        print(state_mean)\n",
    "    return output      \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def flatten(t):\n",
    "    return [item for sublist in t for item in sublist]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preds_trn_flat = flatten(preds_trn)\n",
    "refs_trn_flat = flatten(refs_trn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "refs_trn_flat = flatten(refs_trn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preds_flat = flatten(preds_n)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "refs_flat = flatten(refs_n)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mean_est = make_rul_preds_mean(preds_flat, preds_trn_flat, y_hmm_trn['RUL'].values, n_states = 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plotting  results for the RUL estimation using training values\n",
    "RMSEPP_rf = np.sqrt(np.mean(np.power(refs_flat-mean_est, 2)))\n",
    "plt.figure(1, figsize=(16,16), frameon=False, dpi=100)\n",
    "plt.plot(refs_flat, times, 'o', label=\"RF, RMSEPP=\".format(RMSEPP_rf))\n",
    "plt.plot(refs_flat, refs_flat, '--')\n",
    "plt.xlabel('Reference')\n",
    "plt.ylabel('Prediction')\n",
    "plt.title('RF regressor for Inverter failure predictions')\n",
    "plt.legend(loc='lower right')\n",
    "#plt.savefig('RF_Inv')\n",
    "plt.ylim(-10, 150)\n",
    "plt.show()\n",
    "\n",
    "print('MSE test: %.3f' % (\n",
    "        # mean_squared_error(y_train, y_train_pred),\n",
    "        mean_squared_error(refs_flat, times)))\n",
    "print('RMSE test: %.3f' % (\n",
    "        # np.sqrt(mean_squared_error(y_train, y_train_pred)),\n",
    "        np.sqrt(mean_squared_error(refs_flat, times))))\n",
    "print('R^2 test: %.3f' % (\n",
    "        # r2_score(y_train, y_train_pred),\n",
    "        r2_score(refs_flat, times)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def make_rul_preds_hit(preds, model, n_states = 10):\n",
    "    # Predicts RUL based on the calculated theoretical hitting times for each state\n",
    "    mean_vals = []\n",
    "    output = np.array(copy.copy(preds))\n",
    "    iters= [0 for i in range(n_states)]\n",
    "    for state in range(n_states-1,0,-1):\n",
    "        # Iterating beckwards through all states - starting at the second to last state and going forwards\n",
    "    \n",
    "        transmat = model.transmat_\n",
    "        probs = transmat[state-1]\n",
    "        steps = 1\n",
    "        \n",
    "        for ind in range(len(probs)):\n",
    "            # Iterating through the probabilities of going to the other states\n",
    "            \n",
    "            if (ind+1) != state:\n",
    "                \n",
    "                # p_ij m_jA - iters is the number of steps from the potential state to state 10\n",
    "                steps += probs[ind] * iters[ind]\n",
    "        # Dividing the sum of p_ij m_jAp_ij by (1-p_i), 1 - probability of staying in current state\n",
    "        iters[state-1] = (steps/(1 - probs[state-1]))/26\n",
    "        # /26 for 26 samples per day to get RUL in days\n",
    "        print(iters)\n",
    "        output = np.where(output == state, steps, output)\n",
    "        mean_vals.append(iters[state-1])  \n",
    "    return output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hit_time = make_rul_preds_hit(preds_flat, lr, n_states = 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plotting results for the hitting time prediction\n",
    "#RMSEPP_rf = np.sqrt(np.mean(np.power(refs_flat-hit_time, 2)))\n",
    "plt.figure(1, figsize=(5, 5), frameon=False, dpi=100)\n",
    "plt.plot(refs_flat, hit_time, 'o', label=\"RF, RMSEPP={0:.2f}\".format(RMSEPP_rf))\n",
    "plt.plot(refs_flat, refs_flat, '--')\n",
    "plt.xlabel('Reference')\n",
    "plt.ylabel('Prediction')\n",
    "plt.ylim(-10, 150)\n",
    "plt.title('RF regressor for Inverter failure predictions')\n",
    "plt.legend(loc='lower right')\n",
    "#plt.savefig('RF_Inv')\n",
    "plt.show()\n",
    "\n",
    "print('MSE test: %.3f' % (\n",
    "        # mean_squared_error(y_train, y_train_pred),\n",
    "        mean_squared_error(refs_flat, hit_time)))\n",
    "print('RMSE test: %.3f' % (\n",
    "        # np.sqrt(mean_squared_error(y_train, y_train_pred)),\n",
    "        np.sqrt(mean_squared_error(refs_flat, hit_time))))\n",
    "print('R^2 test: %.3f' % (\n",
    "        # r2_score(y_train, y_train_pred),\n",
    "        r2_score(refs_flat, hit_time)))\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Preparing data for sankey plot, mapping the state transitions\n",
    "\n",
    "source = []\n",
    "target = []\n",
    "value = []\n",
    "for num in range(len(predictions)):\n",
    "    for i in range(len(predictions[num])):\n",
    "        if predictions[num][i]!=predictions[num][i-1] and i > 0 and len(predictions[num])>1:\n",
    "            source.append(predictions[num][i-1])\n",
    "            target.append(predictions[num][i])\n",
    "            value.append(refs[num][i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Making a Sankey plot for the HMM predicted state transitions\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=[go.Sankey(\n",
    "    node = dict(\n",
    "      pad = 15,\n",
    "      thickness = 20,\n",
    "      line = dict(color = \"black\", width = 0.5),\n",
    "      label = [state for state in range(1,11)],\n",
    "      color = \"blue\"\n",
    "    ),\n",
    "    link = dict(\n",
    "      source = source, # indices correspond to labels, eg A1, A2, A1, B1, ...\n",
    "      target = target,\n",
    "      value = value,\n",
    "    hovertemplate='This link has total value %{value}<extra></extra>'\n",
    "  ))])\n",
    "\n",
    "fig.update_layout(title_text=\"Sankey plot for state transition\", font_size=20, title_x=0.5)\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Preparing the HMM prediction data for comparison by confusion matrix\n",
    "\n",
    "LastPoint_states_2 = []\n",
    "LastPoint_RUL_2 = []\n",
    "for cyc in range(len(predictions)):\n",
    "    LastPoint_states_2.append(predictions[cyc][-1])\n",
    "    LastPoint_RUL_2.append(refs[cyc][-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Data preparation for TSFRESH-RFR method\n",
    "\n",
    "RUL = recycled_raw.drop(['RUL'],axis = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "recycled_raw = recycled_raw.drop('RUL', axis = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Removing unneccesary columns\n",
    "recycled_raw = recycled_raw.drop(['ERR00', 'ERR01', 'ERR02', 'ERR03', 'ERR04', 'ERR05', 'ERR06', \n",
    "                                  'ERR07', 'ERR08', 'ERR09', 'ERR10', 'ERR11', 'ERR12', 'ERR13', \n",
    "                                  'ERR14', 'ERR15', 'Error_Word_0','Error_Word_1','Error_Word_10',\n",
    "                                  'Error_Word_11','Error_Word_12','Error_Word_13','Error_Word_14',\n",
    "                                  'Error_Word_15','Error_Word_2','Error_Word_3','Error_Word_4',\n",
    "                                  'Error_Word_5','Error_Word_6','Error_Word_7','Error_Word_8',\n",
    "                                  'Error_Word_9'], axis = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Running the feature extraction with TSFRESH\n",
    "from tsfresh.feature_extraction import extract_features\n",
    "fresh_cycle = extract_features(recycled_raw, column_id=\"Cycle_ID\", column_sort=\"rowid_inv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Finding the ground truth for each maintenance cycle\n",
    "RULs = [min(recycled_raw['RUL'][(recycled_raw['Cycle_ID']==cycle)]) for cycle in np.unique(recycled_raw['Cycle_ID'])]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Performing imputation and feature selection for the extracted data\n",
    "from tsfresh import select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "\n",
    "impute(X)\n",
    "features_filtered = select_features(X, RULs);\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Splitting the training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_filtered, RULs, test_size=0.3, random_state = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Running hyperparameter tuning for the Random Forest regressor\n",
    "results_mse = pd.DataFrame(index = range(100, 500, 100))\n",
    "results_rmse = pd.DataFrame(index = range(100, 500, 100))\n",
    "results_r2 = pd.DataFrame(index = range(100, 500, 100))\n",
    "for mdepth in tqdm(range(5,30,5)):\n",
    "    colres_mse = []\n",
    "    colres_rmse = []\n",
    "    colres_r2 = []\n",
    "    for n_est in range(100, 500, 100):\n",
    "        mser = []\n",
    "        rmser = []\n",
    "        r2r = []\n",
    "        for rs in range(5):\n",
    "            forest = RF(n_jobs = -2, max_depth = mdepth, n_estimators = n_est, random_state = rs)\n",
    "\n",
    "            forest.fit(X_train, y_train)\n",
    "            y_pred_forest = forest.predict(X_test)\n",
    "            \n",
    "            mser.append(mean_squared_error(y_test, y_pred_forest))\n",
    "            rmser.append(np.sqrt(mean_squared_error(y_test, y_pred_forest)))\n",
    "            r2r.append(r2_score(y_test, y_pred_forest))\n",
    "            # y_all = np.vstack([y_test.values,y_pred])\n",
    "        colres_mse.append(np.mean(mser))\n",
    "        colres_rmse.append(np.mean(rmser))\n",
    "        colres_r2.append(np.mean(r2r))\n",
    "    results_rmse[mdepth] = colres_rmse\n",
    "    results_mse[mdepth] = colres_mse\n",
    "    results_r2[mdepth] = colres_r2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "round(results_rmse,2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "round(results_mse,2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "round(results_r2,3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Running RUL predxiction using RFR\n",
    "forest = RF(n_jobs = -3, max_depth = 10, n_estimators = 400)\n",
    "\n",
    "forest.fit(X_train, y_train)\n",
    "y_pred_forest= forest.predict(X_test)\n",
    "\n",
    "\n",
    "RMSEPP_rf = np.sqrt(np.mean(np.power(y_test-y_pred_forest, 2)))\n",
    "plt.figure(1, figsize=(10, 10), frameon=False, dpi=100)\n",
    "plt.plot(y_test, y_pred_forest, 'o', label=\"RF, RMSEPP={0:.2f}\".format(RMSEPP_rf))\n",
    "plt.plot(y_test, y_test, '--')\n",
    "plt.xlabel('Reference')\n",
    "plt.ylabel('Prediction')\n",
    "plt.xlim(0,70)\n",
    "plt.ylim(0,80)\n",
    "plt.title('RF regressor for Inverter failure predictions with feature extraction')\n",
    "plt.legend(loc='lower right')\n",
    "#plt.savefig('RF_Inv_med')\n",
    "plt.show()\n",
    "\n",
    "print('MSE test: %.3f' % (\n",
    "        # mean_squared_error(y_train, y_train_pred),\n",
    "        mean_squared_error(y_test, y_pred_forest)))\n",
    "print('RMSE test: %.3f' % (\n",
    "        # np.sqrt(mean_squared_error(y_train, y_train_pred)),\n",
    "        np.sqrt(mean_squared_error(y_test, y_pred_forest))))\n",
    "print('R^2 test: %.3f' % (\n",
    "        # r2_score(y_train, y_train_pred),\n",
    "        r2_score(y_test, y_pred_forest)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Preparing test data for plotting\n",
    "\n",
    "predictions_rf = [[] for num in range(250)]\n",
    "ground_truth = [[] for num in range(250)]\n",
    "for num in range(len(y_pred_forest)):\n",
    "    predictions_rf[int(y_test[num])].append(y_pred_forest[num])\n",
    "    ground_truth[int(y_test[num])].append(y_test[num])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "errors = [[] for num in range(250)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions = [p for p in predictions if str(p) != 'nan']\n",
    "ground_truth = [g for g in ground_truth if str(g) != 'nan']\n",
    "predictions_rf = [p for p in predictions_rf if len(p) > 0]\n",
    "ground_truth = [g for g in ground_truth if len(g) > 0]\n",
    "#errors = [e for e in errors if str(e) != 'nan']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for num in range(len(predictions_rf)):\n",
    "    errors[num] = np.std(predictions_rf[num])\n",
    "    predictions_rf[num] = np.mean(predictions_rf[num])\n",
    "    ground_truth[num] = np.mean(ground_truth[num])\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plotting Test results for TSFRESH + RFR with error bars\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(layout = go.Layout(\n",
    "title = 'Predictions of remaining useful lifetime, with error bars showing mean error',\n",
    "yaxis = dict(title = 'Predicted RUL [Days]'),\n",
    "xaxis = dict(title = 'Actual RUL [Days]'),\n",
    "                 width=1000, height=800),  \n",
    "                data=go.Scatter(\n",
    "        x=ground_truth,\n",
    "        y=predictions_rf,\n",
    "        error_y=dict(\n",
    "            type='data', # value of error bar given in data coordinates\n",
    "            array=errors,\n",
    "            visible=True), name = 'Prediction mean values'\n",
    "    ))\n",
    "fig.update_layout(title_text='Predictions of RUL, with error bars showing standard deviation', title_x=0.5)\n",
    "fig.update_layout(\n",
    "    font_family=\"Calibri\",\n",
    "    font_color=\"black\",\n",
    "    title_font_family=\"Calibri\",\n",
    "    title_font_color=\"black\",\n",
    "    font_size = 22\n",
    ")\n",
    "fig.update_layout(\n",
    "    legend_font_size = 20\n",
    ")\n",
    "fig.update_layout(legend=dict(\n",
    "    yanchor=\"bottom\",\n",
    "    y=0.1,\n",
    "    xanchor=\"right\",\n",
    "    x=0.99\n",
    "))\n",
    "fig.add_trace(go.Scatter(x=y_test, y=y_pred_forest, mode = \"markers\", name = 'Predictions'))\n",
    "fig.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Finding and displaying feature importances by the RFR\n",
    "imps = forest.feature_importances_\n",
    "\n",
    "importances = {}\n",
    "for num, impo in enumerate(imps):\n",
    "    if impo > 0:\n",
    "        print(X_train.columns[num], impo)\n",
    "        importances[X_train.columns[num]] = impo\n",
    "\n",
    "importances = sorted(importances.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "df_imp = pd.DataFrame(importances)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_imp.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def risk_classes(pred):\n",
    "    # Translates RUL into a risk class for ground truth and predicted RUL\n",
    "    res = copy.copy(pred)\n",
    "    res = np.where(res<=5,0,res)\n",
    "    res = np.where(np.logical_and(res>5, res<=20),1,res)\n",
    "    res = np.where(res>20,2,res)\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def risk_classes_hmm(pred):\n",
    "    # Translates predicted hidden state infor a risk class\n",
    "    res = copy.copy(pred)\n",
    "    res = np.where(res<=4,2,res)\n",
    "    res = np.where(np.logical_and(res>4, res<=7),1,res)\n",
    "    res = np.where(res>7,0,res)\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "forest_classes = risk_classes(y_pred_forest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gt_classes_rf = risk_classes(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hmm_classes_n = risk_classes_hmm(np.array(LastPoint_states_2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gt_classes_hmm_n = risk_classes(np.array(LastPoint_RUL_2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f1_rf = f1_score(gt_classes_rf, forest_classes, average = 'macro')\n",
    "print('f1-score for TSFRESH-RFR method: ', f1_rf)\n",
    "\n",
    "f1_hmm = f1_score(gt_classes_hmm, hmm_classes, average = 'micro')\n",
    "print('f1-score for PCA HMM method: ',f1_hmm)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Creating and plotting confusion matrices for the two methods\n",
    "from sklearn.metrics import confusion_matrix\n",
    "hmm_confmat = confusion_matrix(gt_classes_hmm_n, hmm_classes_n)\n",
    "rf_confmat = confusion_matrix(gt_classes_rf, forest_classes)\n",
    "sns.set(font_scale=3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = sns.heatmap(rf_confmat, annot = True,yticklabels = range(1,4),xticklabels = range(1,4))\n",
    "a.set_xlabel('Predicted class')\n",
    "a.set_ylabel('True class')\n",
    "a.set_title('Confusion matrix for TSFRESH Random Forest Regressor method')\n",
    "plt.savefig('RF_Confplot')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "b = sns.heatmap(hmm_confmat, annot = True,yticklabels = range(1,4),xticklabels = range(1,4))\n",
    "b.set_xlabel('Predicted class')\n",
    "b.set_ylabel('True class')\n",
    "b.set_title('Confusion matrix for PCA HMM method')\n",
    "plt.savefig('HMM_confmat')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}